## Big Data with examples and types
The term itself explains what Big Data is Big which means something that is huge and data which means information, combined big data means huge information. So big data contains that huge amount of information that it becomes difficult to process it. As the world is running with data, storing data is very important, and using the stored information wisely is more important. Processing the Big data takes the steps like collecting the data from different places, storing the data in an organized manner, using the necessary data when needed, and gaining insights from the data for business purposes. To process the data different kinds of tools and techniques are used.  
There are so many examples of big data as it is everywhere in our daily lives. The amount of information that is generated by social networks in the form of images, large videos, and texts. Data is generated by healthcare organizations, commercial websites, banking applications and many others.
Big data is of three different types
### Structured Data
Structured data is organized data, that is easy to access, read and manipulate. For example, employee details in a company like their personal details, job specifications, salaries, and others are stored in a structured format.
### Unstructured Data
Structured data is unorganized data, that is difficult to access, read and manipulate. It takes a lot of time and effort to gain insights from unstructured data. Email is an example of unstructured data, containing spam mails that are difficult to separate from original ones.
### Semi Structured Data
Semi-Structured data is a combination of both structured and unstructured. It contains data that is important but unorganized mostly.
## 6 V's of Big Data
### Volume
As described the volume of big data is so huge and it takes a lot of effort to process and gain insights from the data. It takes multiple machines, tools, and techniques to store and use them when needed.
### Velocity
As the term velocity relates to speed, data that is generated with speed like real-time data should be able to get updated to the old data effectively. So that the data is up to date with new information stored.
### Variety
There is a wide variety of data that are structured, unstructured, and semi-structured that includes texts, audio, video, image, and sensor forms of data.
### Variability
Variability refers to inconsistency, that is the way the data gets changed from time to time. Stock market data changes all the time it is never fixed or consistent.
### Veracity
Veracity refers to the accuracy and quality of the data. The data must be maintained with relevant information so that gaining insights from the data will be achieved accurately.
### value
Data has immense value as we gain useful information from it. Everyone's intention for storing a large amount of data is to gain something valuable from it. 
## Phases of Big Data Analysis
### Phase 1: Data Acquisition and Recording
In this phase data is collected from diffrent sources. As it is collected from different sources it would be unstructured or would contain noise. That noise is filtered using different techniques and tools. After obtaining data without noise it should recorded for future use.
### Phase 2: Information Extraction and Cleaning
Even after filteing the data without noise, we may need only some part of data for some analysis. At that time only the required data is extracted. As we concentrate on required amount of data, cleaning and gaining insights from the data becomes easy. Data Cleaning is the process of preparing the data without inconsistencies or noise.
### Phase 3: Data Integration, Aggregation, and Representation
If there are multiple datasets with some part of common information, then they can be joined using that common information. It helps in reducing inconsistencies and redundancies. Representation of the data in the form of charts, plots, pictures or maps makes it easy for the people to understand.
### Phase 4: Query Processing, Data Modeling, and Analysis
Queries are used to obtain only the required part of data from the whole dataset. Data modeling provides us with an abstract or blue print of the data. Through that we can know what information does the dataset contain. Analysis is the process of gaining insights from the data. We can get trends or patterns from the data.
### Phase 5: Interpretation
If we are not sure about some information in the dataset. we can interpret that information through the patterns observed in the visualization and analysis process. Interpreted results can be used in business for decision making.
